{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da56f31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/bvandelft/Projects/Audio/clearaudio\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c249c0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "from clearaudio.utils.wavenet_utils import (\n",
    "    overlap_and_add_samples,\n",
    "    cut_track_stack,\n",
    "    linear_pcm,\n",
    "    generate_waveform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90aeaba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_track_stack(audio_input_tensor, window_length=8192*2**4, overlap=0.5):\n",
    "    \"\"\"\n",
    "    Cuts a given track in overlapping windows and stacks them along a new axis\n",
    "    :param track_path: path to .wav track to apply the function on\n",
    "    :param window_length: number of samples per window (scalar int)\n",
    "    :param overlap: ratio of overlapping samples for consecutive samples (scalar int in [0, 1))\n",
    "    :return: processed track as a numpy array with dimension [window_number, 1, window_length], sampling frequency\n",
    "    \"\"\"\n",
    "    track = audio_input_tensor\n",
    "    # Get number of windows and prepare empty array\n",
    "    window_number = compute_window_number(track_length=track.size(-1), window_length=window_length,overlap=overlap)\n",
    "    print(window_number)\n",
    "    bsz = track.size(0)\n",
    "    #cut_track = np.zeros((window_number, window_length))\n",
    "    cut_track = torch.zeros((bsz,window_number, window_length))\n",
    "    # Cut the tracks in smaller windows\n",
    "    for music_index in range(bsz):\n",
    "        for i in range(window_number):\n",
    "            window_start = int(i * (1 - overlap) * window_length)\n",
    "            window = track[:,window_start: window_start + window_length]\n",
    "\n",
    "            # Check if last window needs padding\n",
    "            if window.size(-1) != window_length:\n",
    "                padding = window_length - window.size(1)\n",
    "                window = torch.cat([window, torch.zeros([bsz,padding])], axis = 1)\n",
    "            cut_track[music_index,i] = window\n",
    "    return cut_track\n",
    "\n",
    "\n",
    "def compute_window_number(track_length: int, window_length: int = 8192*2**5, overlap: float = 0.5):\n",
    "    \"\"\"\n",
    "    Computes the number of overlapping window for a specific track.\n",
    "    :param track_length: total number of samples in the track (scalar int).\n",
    "    :param window_length: number of samples per window (scalar int).\n",
    "    :param overlap: ratio of overlapping samples for consecutive samples (scalar int in [0, 1))\n",
    "    :return: number of windows in the track\n",
    "    \"\"\"\n",
    "    num = track_length - window_length\n",
    "    den = window_length * (1 - overlap)\n",
    "    return int(num // den + 2)\n",
    "\n",
    "\n",
    "# def overlap_and_add_samples(clean_tracks, equalized_tracks, generated_tracks, overlap, window_length, use_windowing=True):\n",
    "#     \"\"\"\n",
    "#     Re-construct a full sample from its sub-parts using the OLA algorithm.\n",
    "#     :param batch: input signal previously split in overlapping windows torch tensor of shape [B, 1, WINDOW_LENGTH].\n",
    "#     :return: reconstructed sample (torch tensor).\n",
    "#     \"\"\"\n",
    "#     assert(clean_tracks.size() == generated_tracks.size())\n",
    "#     # Compute the size of the full sample\n",
    "\n",
    "#     bsz, window_number, single_sample_size = equalized_tracks.size()\n",
    "#     full_sample_size = int(single_sample_size * (1 + (window_number - 1) * (1 - overlap)))\n",
    "\n",
    "#     # Initialize the full sample\n",
    "    \n",
    "#     clean_full = torch.zeros((bsz,full_sample_size))\n",
    "#     equalized_full = torch.zeros((bsz,full_sample_size))\n",
    "#     generated_full = torch.zeros((bsz,full_sample_size))\n",
    "#     # print(clean_full.size())\n",
    "#     if use_windowing:\n",
    "#         hanning = torch.from_numpy(np.hanning(window_length))\n",
    "\n",
    "#     for batch in range(bsz):\n",
    "#         for window_index in range(window_number):\n",
    "#             window_start = int(window_index * (1 - overlap) * window_length)\n",
    "#             window_end = window_start + window_length\n",
    "           \n",
    "#             clean_sample= clean_tracks[batch,window_index].squeeze()\n",
    "#             equalized_sample = equalized_tracks[batch,window_index].squeeze()\n",
    "#             generated_sample = generated_tracks[batch,window_index].squeeze()\n",
    "\n",
    "#             if use_windowing:               \n",
    "#                 generated_sample *= hanning\n",
    "#                 clean_sample *= hanning\n",
    "#                 equalized_sample *= hanning\n",
    "#             clean_full[batch,window_start: window_end] += clean_sample\n",
    "#             equalized_full[batch,window_start: window_end] += equalized_sample\n",
    "#             generated_full[batch,window_start: window_end] += generated_sample\n",
    "            \n",
    "#         return clean_full, equalized_full,generated_full\n",
    "\n",
    "\n",
    "def overlap_and_add_samples(samples_tensor: torch.Tensor, overlap: float, window_length: int, use_windowing: bool = True) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Re-construct a full sample from its sub-parts using the OLA algorithm.\n",
    "    :param batch: input signal previously split in overlapping windows torch tensor of shape [B, 1, WINDOW_LENGTH].\n",
    "    :return: reconstructed sample (torch tensor).\n",
    "    \"\"\"\n",
    "    # Compute the size of the full sample\n",
    "    bsz, window_number, single_sample_size = samples_tensor.size()\n",
    "    full_sample_size = int(single_sample_size * (1 + (window_number - 1) * (1 - overlap)))\n",
    "\n",
    "    # Initialize the full sample\n",
    "    full = torch.zeros((bsz, full_sample_size))\n",
    "\n",
    "    if use_windowing:\n",
    "        hanning = torch.from_numpy(np.hanning(window_length))\n",
    "\n",
    "    for batch in range(bsz):\n",
    "        for window_index in range(window_number):\n",
    "            window_start = int(window_index * (1 - overlap) * window_length)\n",
    "            window_end = window_start + window_length\n",
    "           \n",
    "            sample = samples_tensor[batch, window_index].squeeze()\n",
    "            if use_windowing:               \n",
    "                sample *= hanning\n",
    "\n",
    "            full[batch,window_start: window_end] += sample\n",
    "        return full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d37fce67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ..., -0.2199, -0.1982, -0.2037]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74861eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, sr = torchaudio.load('samples/hq/starwars.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2c7686b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n"
     ]
    }
   ],
   "source": [
    "cts = cut_track_stack(sample[:, :2**8+3], window_length=2**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a018637a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 260])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_and_add_samples(cts, window_length=2**2, overlap=0.5).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_window = int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4e234f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66d4b2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "342e8363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 7, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cts.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3b8c509a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 16])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_and_add_samples(cts,window_length=2**2, overlap=0.5).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db178564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[:, :2**8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17647a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResConv1DBlock(nn.Module):\n",
    "    def __init__(self, n_in, n_state, dilation=1, zero_out=False, res_scale=1.0):\n",
    "        super().__init__()\n",
    "        padding = dilation\n",
    "        self.model = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n_in, n_state, 3, 1, padding='same', dilation=dilation),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(n_state, n_in, 1, 1, 0),\n",
    "        )\n",
    "        if zero_out:\n",
    "            out = self.model[-1]\n",
    "            nn.init.zeros_(out.weight)\n",
    "            nn.init.zeros_(out.bias)\n",
    "        self.res_scale = res_scale\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = x + self.res_scale * self.model(x)       \n",
    "        return y\n",
    "\n",
    "class Resnet1D(nn.Module):\n",
    "    def __init__(self, n_in, n_depth, m_conv=1.0, dilation_growth_rate=1, dilation_cycle=None, zero_out=False, res_scale=False):\n",
    "        super().__init__()\n",
    "        def _get_depth(depth):\n",
    "            if dilation_cycle is None:\n",
    "                return depth\n",
    "            else:\n",
    "                return depth % dilation_cycle\n",
    "        blocks = [ResConv1DBlock(n_in, int(m_conv * n_in),\n",
    "                                 dilation=dilation_growth_rate ** _get_depth(depth),\n",
    "                                 zero_out=zero_out,\n",
    "                                 res_scale=1.0 if not res_scale else 1.0 / math.sqrt(n_depth))\n",
    "                  for depth in range(n_depth)]\n",
    "\n",
    "        self.model = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.model(x)\n",
    "        print(\"ResNet : \", y.size())\n",
    "        return y #self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db84013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.block = nn.Sequential(\n",
    "            GroupNorm(in_channels),\n",
    "            Swish(),\n",
    "            nn.Conv1d(in_channels, out_channels, 3, 1, 1),\n",
    "            GroupNorm(out_channels),\n",
    "            Swish(),\n",
    "            nn.Conv1d(out_channels, out_channels, 3, 1, 1)\n",
    "        )\n",
    "        if in_channels != out_channels:\n",
    "            self.channel_up = nn.Conv1d(in_channels, out_channels, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.in_channels != self.out_channels:\n",
    "            return self.block(x) + self.channel_up(x)\n",
    "        else:\n",
    "            return x + self.block(x)\n",
    "\n",
    "\n",
    "class UpSampleBlock(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out, kernel_size = 3, stride = 2, pad = 1, mode=\"pixel_shuffle\"):\n",
    "        super(UpSampleBlock, self).__init__()\n",
    "        self.scale_factor = stride\n",
    "        self.mode = mode\n",
    "        if self.mode == 'interpolate':\n",
    "            self.conv = nn.Conv1d(channels_in, channels_out, kernel_size, padding = 'same')\n",
    "        elif self.mode == 'transpose_conv':\n",
    "            self.conv = nn.ConvTranspose1d(channels_in, channels_out, kernel_size, stride, pad)\n",
    "        elif self.mode == \"pixel_shuffle\":\n",
    "            self.conv = nn.Conv1d(channels_in, channels_in*self.scale_factor, kernel_size, padding = 'same')\n",
    "            self.shuffle = nn.PixelShuffle(self.scale_factor)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(self.mode)\n",
    "        if self.mode == 'interpolate':\n",
    "            x = F.interpolate(x, scale_factor=self.scale_factor)\n",
    "            return self.conv(x)\n",
    "        elif self.mode == \"pixel_shuffle\":\n",
    "            zeros_size = x.size(1)*self.scale_factor**2-x.size(1)*self.scale_factor ### Fill the channels with enough 0 to make a 2-D pixel shuffling\n",
    "            zeros = torch.zeros(x.size(0), zeros_size, x.size(2)).detach()\n",
    "            x_prime = torch.cat((self.conv(x), zeros), dim=1).unsqueeze(-1)\n",
    "            y = self.shuffle(x_prime)[:,:,::self.scale_factor,:].contiguous().view(1,x.size(1),-1)\n",
    "            return y\n",
    "        elif self.mode == \"transpose_conv\":\n",
    "            return self.conv(x)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "\n",
    "\n",
    "class DownSampleBlock(nn.Module):\n",
    "    def __init__(self, channels, kernel_size = 3, stride_t = 2, pad_t = 0):\n",
    "        super(DownSampleBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(channels, channels, kernel_size, stride_t, pad_t)        \n",
    "    def forward(self, x):\n",
    "#         pad = (0, 1, 0, 1)\n",
    "#         x = F.pad(x, pad, mode=\"constant\", value=0)\n",
    "        print(x.size())\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class NonLocalBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "\n",
    "        self.norm = GroupNorm(in_channels)\n",
    "        self.q = torch.nn.Conv1d(in_channels, in_channels, 1, 1, 0)\n",
    "        self.k = torch.nn.Conv1d(in_channels, in_channels, 1, 1, 0)\n",
    "        self.v = torch.nn.Conv1d(in_channels, in_channels, 1, 1, 0)\n",
    "        self.proj_out = torch.nn.Conv1d(in_channels, in_channels, 1, 1, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_ = self.norm(x)\n",
    "        q = self.q(h_)\n",
    "        k = self.k(h_)\n",
    "        v = self.v(h_)\n",
    "\n",
    "        b, c, h, w = q.shape\n",
    "\n",
    "        q = q.reshape(b, c, h * w)\n",
    "        q = q.permute(0, 2, 1)\n",
    "        k = k.reshape(b, c, h * w)\n",
    "        v = v.reshape(b, c, h * w)\n",
    "\n",
    "        attn = torch.bmm(q, k)\n",
    "        attn = attn * (int(c) ** (-0.5))\n",
    "        attn = F.softmax(attn, dim=2)\n",
    "\n",
    "        attn = attn.permute(0, 2, 1)\n",
    "        A = torch.bmm(v, attn)\n",
    "        A = A.reshape(b, c, h, w)\n",
    "\n",
    "        A = self.proj_out(A)\n",
    "\n",
    "        return x + A\n",
    "\n",
    "\n",
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(GroupNorm, self).__init__()\n",
    "        self.gn = nn.GroupNorm(num_groups=32, num_channels=in_channels, eps=1e-6, affine=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gn(x)\n",
    "\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.in_channels = 1\n",
    "        self.width = 128\n",
    "        self.output_channels = 64\n",
    "        self.depth = 2\n",
    "        self.m_conv = 1.0\n",
    "        self.dilation_growth_rate = 3\n",
    "        self.dilation_cycle = None\n",
    "        self.zero_out = False\n",
    "        self.res_scale = False\n",
    "        blocks = []\n",
    "        stride_t = 2\n",
    "        blocks.append(nn.Conv1d(self.in_channels, self.width, 31, 1, padding='same'))\n",
    "        for i in range(3):\n",
    "            kernel_size, pad_t = stride_t * 2, stride_t // 2\n",
    "            block = nn.Sequential(\n",
    "                    DownSampleBlock(self.width, kernel_size, stride_t, pad_t),\n",
    "                    Resnet1D(self.width, self.depth, self.m_conv, self.dilation_growth_rate, self.dilation_cycle, self.zero_out, self.res_scale),\n",
    "                )\n",
    "            blocks.append(block)\n",
    "        block = nn.Conv1d(self.width, self.output_channels, 31, 1, padding='same')\n",
    "        blocks.append(block)\n",
    "\n",
    "        self.model = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, kernel_size = None, output_classes = None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.first_kernel_size = 32\n",
    "        self.in_channels = 64\n",
    "        self.width = 128\n",
    "        self.stride_t = 2\n",
    "        self.depth = 2\n",
    "        self.m_conv = 1.0\n",
    "        self.dilation_growth_rate = 3\n",
    "        self.dilation_cycle = None\n",
    "        self.zero_out = False\n",
    "        self.res_scale = False\n",
    "\n",
    "        blocks = []\n",
    "        if kernel_size is None:\n",
    "            self.kernel_size, pad_t = self.stride_t * 2, self.stride_t // 2\n",
    "        else:\n",
    "            self.kernel_size = kernel_size\n",
    "        \n",
    "        block = nn.Conv1d(self.in_channels, self.width, self.first_kernel_size, 1, padding='same')\n",
    "        blocks.append(block)\n",
    "        for i in range(3):\n",
    "            block = nn.Sequential(\n",
    "                    Resnet1D(self.width, self.depth, self.m_conv, self.dilation_growth_rate, self.dilation_cycle, zero_out=self.zero_out, res_scale=self.res_scale),\n",
    "                    UpSampleBlock(self.width, self.width, self.kernel_size, self.stride_t, pad_t)\n",
    "                )\n",
    "            blocks.append(block)\n",
    "        \n",
    "        blocks.append(GroupNorm(self.width))\n",
    "        blocks.append(Swish())\n",
    "        if output_classes is None:\n",
    "            self.output_classes = 1\n",
    "        else:\n",
    "            self.output_classes = output_classes\n",
    "        blocks.append(nn.Conv1d(self.width, self.output_classes, kernel_size=64, stride=1, padding=1))\n",
    "        self.model = nn.Sequential(*blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2f48fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BottleneckBlock(nn.Module):\n",
    "    def __init__(self, k_bins, emb_width, mu):\n",
    "        super().__init__()\n",
    "        self.k_bins = k_bins\n",
    "        self.emb_width = emb_width\n",
    "        self.mu = mu\n",
    "        self.reset_k()\n",
    "        self.threshold = 1.0\n",
    "\n",
    "    def reset_k(self):\n",
    "        self.init = False\n",
    "        self.k_sum = None\n",
    "        self.k_elem = None\n",
    "        self.register_buffer('k', torch.zeros(self.k_bins, self.emb_width))\n",
    "\n",
    "    def _tile(self, x):\n",
    "        d, ew = x.shape\n",
    "        if d < self.k_bins:\n",
    "            n_repeats = (self.k_bins + d - 1) // d\n",
    "            std = 0.01 / np.sqrt(ew)\n",
    "            x = x.repeat(n_repeats, 1)\n",
    "            x = x + torch.randn_like(x) * std\n",
    "        return x\n",
    "\n",
    "    def init_k(self, x):\n",
    "        mu, emb_width, k_bins = self.mu, self.emb_width, self.k_bins\n",
    "        self.init = True\n",
    "        # init k_w using random vectors from x\n",
    "        y = self._tile(x)\n",
    "        _k_rand = y[torch.randperm(y.shape[0])][:k_bins]\n",
    "#         dist.broadcast(_k_rand, 0)\n",
    "        self.k = _k_rand\n",
    "        assert self.k.shape == (k_bins, emb_width)\n",
    "        self.k_sum = self.k\n",
    "        self.k_elem = torch.ones(k_bins, device=self.k.device)\n",
    "\n",
    "    def restore_k(self, num_tokens=None, threshold=1.0):\n",
    "        mu, emb_width, k_bins = self.mu, self.emb_width, self.k_bins\n",
    "        self.init = True\n",
    "        assert self.k.shape == (k_bins, emb_width)\n",
    "        self.k_sum = self.k.clone()\n",
    "        self.k_elem = torch.ones(k_bins, device=self.k.device)\n",
    "        if num_tokens is not None:\n",
    "            expected_usage = num_tokens / k_bins\n",
    "            self.k_elem.data.mul_(expected_usage)\n",
    "            self.k_sum.data.mul_(expected_usage)\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def update_k(self, x, x_l):\n",
    "        mu, emb_width, k_bins = self.mu, self.emb_width, self.k_bins\n",
    "        with torch.no_grad():\n",
    "            # Calculate new centres\n",
    "            x_l_onehot = torch.zeros(k_bins, x.shape[0], device=x.device)  # k_bins, N * L\n",
    "            x_l_onehot.scatter_(0, x_l.view(1, x.shape[0]), 1)\n",
    "            print(f\"xl : {x_l}, {x_l.size()}\")\n",
    "            print(f\"x_l_onehot : {x_l_onehot},{x_l_onehot.sum(0)} {x_l_onehot.size()}\")\n",
    "            _k_sum = torch.matmul(x_l_onehot, x)  # k_bins, w\n",
    "            _k_elem = x_l_onehot.sum(dim=-1)  # k_bins\n",
    "            y = self._tile(x)\n",
    "            _k_rand = y[torch.randperm(y.shape[0])][:k_bins]\n",
    "\n",
    "#             dist.broadcast(_k_rand, 0)\n",
    "#             dist.all_reduce(_k_sum)\n",
    "#             dist.all_reduce(_k_elem)\n",
    "\n",
    "            # Update centres\n",
    "            old_k = self.k\n",
    "            self.k_sum = mu * self.k_sum + (1. - mu) * _k_sum  # w, k_bins\n",
    "            print(f\"k_sum : {self.k_sum}, {self.k_sum.size()}\")\n",
    "            self.k_elem = mu * self.k_elem + (1. - mu) * _k_elem  # k_bins\n",
    "            print(f\"k_elem : {self.k_elem}, {self.k_elem.size()}\")\n",
    "            usage = (self.k_elem.view(k_bins, 1) >= self.threshold).float()\n",
    "            print(f\"usage 1st : {usage}, {usage.size()}\")\n",
    "            self.k = usage * (self.k_sum.view(k_bins, emb_width) / self.k_elem.view(k_bins, 1)) \\\n",
    "                     + (1 - usage) * _k_rand\n",
    "            _k_prob = _k_elem / torch.sum(_k_elem)  # x_l_onehot.mean(dim=-1)  # prob of each bin\n",
    "            entropy = -torch.sum(_k_prob * torch.log(_k_prob + 1e-8))  # entropy ie how diverse\n",
    "            used_curr = (_k_elem >= self.threshold).sum()\n",
    "            usage = torch.sum(usage)\n",
    "            print(f\"usage 2nd : {usage}, {usage.size()}\")\n",
    "            dk = torch.norm(self.k - old_k) / np.sqrt(np.prod(old_k.shape))\n",
    "        return dict(entropy=entropy,\n",
    "                    used_curr=used_curr,\n",
    "                    usage=usage,\n",
    "                    dk=dk)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        # NCT -> NTC -> [NT, C]\n",
    "        x = x.permute(0, 2, 1).contiguous()\n",
    "        x = x.view(-1, x.shape[-1])  # x_en = (N * L, w), k_j = (w, k_bins)\n",
    "\n",
    "        if x.shape[-1] == self.emb_width:\n",
    "            prenorm = torch.norm(x - torch.mean(x)) / np.sqrt(np.prod(x.shape))\n",
    "#         elif x.shape[-1] == 2 * self.emb_width:\n",
    "#             x1, x2 = x[...,:self.emb_width], x[...,self.emb_width:]\n",
    "#             prenorm = (torch.norm(x1 - torch.mean(x1)) / np.sqrt(np.prod(x1.shape))) + (torch.norm(x2 - torch.mean(x2)) / np.sqrt(np.prod(x2.shape)))\n",
    "\n",
    "#             # Normalise\n",
    "#             x = x1 + x2\n",
    "        else:\n",
    "            assert False, f\"Expected {x.shape[-1]} to be (1 or 2) * {self.emb_width}\"\n",
    "        return x, prenorm\n",
    "\n",
    "    def postprocess(self, x_l, x_d, x_shape):\n",
    "        # [NT, C] -> NTC -> NCT\n",
    "        N, T = x_shape\n",
    "        x_d = x_d.view(N, T, -1).permute(0, 2, 1).contiguous()\n",
    "        x_l = x_l.view(N, T)\n",
    "        return x_l, x_d\n",
    "\n",
    "    def quantise(self, x):\n",
    "        # Calculate latent code x_l\n",
    "        k_w = self.k.t()\n",
    "        print(\"x\",x.size())\n",
    "        print(\"k_w\",k_w.size())\n",
    "        print(\"x**2\", torch.matmul(x, k_w).size())\n",
    "        distance = torch.sum(x ** 2, dim=-1, keepdim=True) - 2 * torch.matmul(x, k_w) + torch.sum(k_w ** 2, dim=0,\n",
    "                                                                                            keepdim=True)  # (N * L, b)\n",
    "        print(\"Distance\", distance, distance.size())\n",
    "        min_distance, x_l = torch.min(distance, dim=-1)\n",
    "        fit = torch.mean(min_distance)\n",
    "        return x_l, fit\n",
    "\n",
    "    def dequantise(self, x_l):\n",
    "        x = F.embedding(x_l, self.k)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        N, width, T = x.shape\n",
    "\n",
    "        # Preprocess.\n",
    "        x, prenorm = self.preprocess(x)\n",
    "\n",
    "        # Quantise\n",
    "        x_l, fit = self.quantise(x)\n",
    "\n",
    "        # Postprocess.\n",
    "        x_l = x_l.view(N, T)\n",
    "        return x_l\n",
    "\n",
    "    def decode(self, x_l):\n",
    "        N, T = x_l.shape\n",
    "        width = self.emb_width\n",
    "\n",
    "        # Dequantise\n",
    "        x_d = self.dequantise(x_l)\n",
    "\n",
    "        # Postprocess\n",
    "        x_d = x_d.view(N, T, width).permute(0, 2, 1).contiguous()\n",
    "        return x_d\n",
    "\n",
    "    def forward(self, x, update_k=True):\n",
    "        N, width, T = x.shape\n",
    "        print(\"begin\",x.shape)\n",
    "        # Preprocess\n",
    "        x, prenorm = self.preprocess(x)\n",
    "        print(\"preprocessed\", x.shape)\n",
    "        # Init k if not inited\n",
    "        if update_k and not self.init:\n",
    "            self.init_k(x)\n",
    "\n",
    "        # Quantise and dequantise through bottleneck\n",
    "        x_l, fit = self.quantise(x)\n",
    "        print(\"fit\", fit)\n",
    "        print('x_l', x_l, x_l.size())\n",
    "        x_d = self.dequantise(x_l)\n",
    "        print('x_d', x_d, x_d.size())\n",
    "        # Update embeddings\n",
    "        if update_k:\n",
    "            update_metrics = self.update_k(x, x_l)\n",
    "        else:\n",
    "            update_metrics = {}\n",
    "\n",
    "        # Loss\n",
    "        commit_loss = torch.norm(x_d.detach() - x) ** 2 / np.prod(x.shape)\n",
    "\n",
    "        # Passthrough\n",
    "        x_d = x + (x_d - x).detach()\n",
    "\n",
    "        # Postprocess\n",
    "        x_l, x_d = self.postprocess(x_l, x_d, (N,T))\n",
    "        print('x_l', x_l, x_l.size())\n",
    "        print('x_d', x_d, x_d.size())\n",
    "        return x_l, x_d, commit_loss, dict(fit=fit,\n",
    "                                           pn=prenorm,\n",
    "                                           **update_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe12fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    def __init__(self, l_bins = 1024, emb_width=64, mu=0.99):\n",
    "        super().__init__()\n",
    "        self.l_bins = l_bins #cfg.trainer.codebook.nb_bins\n",
    "        self.emb_channels = emb_width #cfg.trainer.vqvae.emb_channels\n",
    "        self.mu = mu\n",
    "        self.model = BottleneckBlock(self.l_bins, self.emb_channels, self.mu)\n",
    "    \n",
    "    def encode(self, xs):\n",
    "        zs = self.model(xs)\n",
    "        return zs\n",
    "\n",
    "    def decode(self, zs):\n",
    "        xs_quantised = self.model.decode(zs)\n",
    "        return xs_quantised\n",
    "\n",
    "    def forward(self, xs):\n",
    "        zs, x_quantised, commit_loss, metric = self.model(xs, update_k=self.training)\n",
    "        return zs, x_quantised, commit_loss, metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7445cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8e03554",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8884e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "codebook = Bottleneck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e7c3d82",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12578/2170553973.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'starwars.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'encoder' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "xs = encoder(sample[0][:,:1024].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d03fbdef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit': tensor(5.9056e-05, grad_fn=<MeanBackward0>),\n",
       " 'pn': tensor(0.0528, grad_fn=<DivBackward0>),\n",
       " 'entropy': tensor(1.6020),\n",
       " 'used_curr': tensor(37),\n",
       " 'usage': tensor(37.),\n",
       " 'dk': tensor(0.0171)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51d19cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin torch.Size([1, 64, 128])\n",
      "preprocessed torch.Size([128, 64])\n",
      "x torch.Size([128, 64])\n",
      "k_w torch.Size([64, 1024])\n",
      "x**2 torch.Size([128, 1024])\n",
      "Distance tensor([[7.9988e-02, 8.0459e-02, 7.8982e-02,  ..., 7.8980e-02, 8.0792e-02,\n",
      "         2.2465e-01],\n",
      "        [7.4519e-02, 7.5183e-02, 7.3220e-02,  ..., 7.3568e-02, 7.5496e-02,\n",
      "         2.1687e-01],\n",
      "        [6.3151e-02, 6.3156e-02, 6.1709e-02,  ..., 6.2160e-02, 6.3529e-02,\n",
      "         2.1286e-01],\n",
      "        ...,\n",
      "        [8.7827e-02, 8.9004e-02, 8.6687e-02,  ..., 8.8687e-02, 8.8546e-02,\n",
      "         9.4470e-03],\n",
      "        [9.2914e-02, 9.4100e-02, 9.1937e-02,  ..., 9.3783e-02, 9.3338e-02,\n",
      "         6.3155e-03],\n",
      "        [1.1348e-01, 1.1484e-01, 1.1233e-01,  ..., 1.1458e-01, 1.1405e-01,\n",
      "         1.3255e-04]], grad_fn=<AddBackward0>) torch.Size([128, 1024])\n",
      "fit tensor(5.9056e-05, grad_fn=<MeanBackward0>)\n",
      "x_l tensor([ 892,  717,  575,  619,  246,  517,  431,  554,   98,  715,  391,  666,\n",
      "         743,   88,  660,  923,    1,  953,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  373,  376, 1001,  223,  659,  489,  949,  631,  300,  729,\n",
      "         518,  967,  433,  890, 1011,  305,  522,  344]) torch.Size([128])\n",
      "x_d tensor([[ 0.0329,  0.0475,  0.0937,  ...,  0.0021, -0.0336, -0.0184],\n",
      "        [ 0.0426,  0.0464,  0.0902,  ..., -0.0041, -0.0359, -0.0009],\n",
      "        [ 0.0524,  0.0328,  0.0999,  ..., -0.0145, -0.0431, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0479,  0.0018,  0.0253,  ..., -0.0571,  0.0874, -0.0072],\n",
      "        [ 0.0410,  0.0094,  0.0231,  ..., -0.0626,  0.0860, -0.0182],\n",
      "        [ 0.0283,  0.0096,  0.0114,  ..., -0.0726,  0.0841, -0.0154]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([128, 64])\n",
      "xl : tensor([ 892,  717,  575,  619,  246,  517,  431,  554,   98,  715,  391,  666,\n",
      "         743,   88,  660,  923,    1,  953,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "         123,  123,  373,  376, 1001,  223,  659,  489,  949,  631,  300,  729,\n",
      "         518,  967,  433,  890, 1011,  305,  522,  344]), torch.Size([128])\n",
      "x_l_onehot : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]),tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.]) torch.Size([1024, 128])\n",
      "k_sum : tensor([[ 0.0673,  0.0552,  0.1051,  ..., -0.0572,  0.0337, -0.0245],\n",
      "        [ 0.0679,  0.0528,  0.1087,  ..., -0.0586,  0.0335, -0.0212],\n",
      "        [ 0.0680,  0.0500,  0.1070,  ..., -0.0579,  0.0346, -0.0196],\n",
      "        ...,\n",
      "        [ 0.0685,  0.0541,  0.1072,  ..., -0.0583,  0.0336, -0.0216],\n",
      "        [ 0.0676,  0.0537,  0.1062,  ..., -0.0587,  0.0357, -0.0214],\n",
      "        [ 0.0267,  0.0083,  0.0120,  ..., -0.0744,  0.0846, -0.0164]]), torch.Size([1024, 64])\n",
      "k_elem : tensor([0.9900, 1.0000, 0.9900,  ..., 0.9900, 0.9900, 0.9900]), torch.Size([1024])\n",
      "usage 1st : tensor([[0.],\n",
      "        [1.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]]), torch.Size([1024, 1])\n",
      "usage 2nd : 37.0, torch.Size([])\n",
      "x_l tensor([[ 892,  717,  575,  619,  246,  517,  431,  554,   98,  715,  391,  666,\n",
      "          743,   88,  660,  923,    1,  953,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,  123,\n",
      "          123,  123,  373,  376, 1001,  223,  659,  489,  949,  631,  300,  729,\n",
      "          518,  967,  433,  890, 1011,  305,  522,  344]]) torch.Size([1, 128])\n",
      "x_d tensor([[[ 0.0329,  0.0426,  0.0524,  ...,  0.0479,  0.0410,  0.0283],\n",
      "         [ 0.0475,  0.0464,  0.0328,  ...,  0.0018,  0.0094,  0.0096],\n",
      "         [ 0.0937,  0.0902,  0.0999,  ...,  0.0253,  0.0231,  0.0114],\n",
      "         ...,\n",
      "         [ 0.0021, -0.0041, -0.0145,  ..., -0.0571, -0.0626, -0.0726],\n",
      "         [-0.0336, -0.0359, -0.0431,  ...,  0.0874,  0.0860,  0.0841],\n",
      "         [-0.0184, -0.0009, -0.0015,  ..., -0.0072, -0.0182, -0.0154]]],\n",
      "       grad_fn=<CloneBackward0>) torch.Size([1, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "zs, x_quantised, commit_loss, metric = codebook(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40ea7a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin torch.Size([1, 64, 128])\n",
      "preprocessed torch.Size([128, 64])\n",
      "x torch.Size([128, 64])\n",
      "k_w torch.Size([64, 1024])\n",
      "x**2 torch.Size([128, 1024])\n",
      "Distance tensor([[0.0983, 0.0974, 0.0962,  ..., 0.0625, 0.0993, 0.0633],\n",
      "        [0.0868, 0.0862, 0.0851,  ..., 0.0494, 0.0880, 0.0542],\n",
      "        [0.0838, 0.0835, 0.0824,  ..., 0.0412, 0.0852, 0.0511],\n",
      "        ...,\n",
      "        [0.1011, 0.1011, 0.1015,  ..., 0.1361, 0.1014, 0.1195],\n",
      "        [0.1163, 0.1162, 0.1163,  ..., 0.1507, 0.1165, 0.1331],\n",
      "        [0.1328, 0.1324, 0.1326,  ..., 0.1637, 0.1330, 0.1425]],\n",
      "       grad_fn=<AddBackward0>) torch.Size([128, 1024])\n",
      "fit tensor(5.6990e-05, grad_fn=<MeanBackward0>)\n",
      "x_l tensor([ 949,  655,  174,  731,  945,  405,  351,  660,  907, 1021,  524,  409,\n",
      "         441,   22,  821,  733,  785,  594,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  941,  782,  288,   75,  452,  688,  825,  491,  569,  948,\n",
      "         116,  391,  858,  150,  685,  938,  743, 1010]) torch.Size([128])\n",
      "x_d tensor([[-0.0453, -0.0150,  0.0558,  ..., -0.0774,  0.0252,  0.0292],\n",
      "        [-0.0447,  0.0003,  0.0724,  ..., -0.0770,  0.0348,  0.0192],\n",
      "        [-0.0489,  0.0227,  0.0685,  ..., -0.0942,  0.0400,  0.0207],\n",
      "        ...,\n",
      "        [ 0.0710,  0.0146,  0.0091,  ..., -0.0350,  0.0116, -0.0194],\n",
      "        [ 0.0568,  0.0082,  0.0196,  ..., -0.0227,  0.0077, -0.0323],\n",
      "        [ 0.0404,  0.0166,  0.0235,  ..., -0.0140,  0.0106, -0.0289]],\n",
      "       grad_fn=<EmbeddingBackward0>) torch.Size([128, 64])\n",
      "xl : tensor([ 949,  655,  174,  731,  945,  405,  351,  660,  907, 1021,  524,  409,\n",
      "         441,   22,  821,  733,  785,  594,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "         563,  563,  941,  782,  288,   75,  452,  688,  825,  491,  569,  948,\n",
      "         116,  391,  858,  150,  685,  938,  743, 1010]), torch.Size([128])\n",
      "x_l_onehot : tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]),tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.]) torch.Size([1024, 128])\n",
      "k_sum : tensor([[ 1.5483e-03,  1.2684e-02,  9.0242e-02,  ..., -8.0802e-02,\n",
      "          7.9081e-03,  9.2034e-03],\n",
      "        [ 8.6833e-04,  1.2731e-02,  8.7857e-02,  ..., -8.0754e-02,\n",
      "          7.9368e-03,  9.6051e-03],\n",
      "        [ 5.6210e-05,  1.2905e-02,  8.9868e-02,  ..., -8.0569e-02,\n",
      "          8.7377e-03,  6.0369e-03],\n",
      "        ...,\n",
      "        [-1.7520e-02,  3.2545e-02,  8.3605e-02,  ..., -9.2725e-02,\n",
      "          5.2695e-02,  2.2705e-02],\n",
      "        [ 1.6249e-03,  1.1804e-02,  8.7967e-02,  ..., -8.3211e-02,\n",
      "          7.1048e-03,  6.7380e-03],\n",
      "        [-2.2335e-02, -3.0846e-03,  8.2459e-02,  ..., -8.7525e-02,\n",
      "          2.2357e-02,  1.5973e-02]]), torch.Size([1024, 64])\n",
      "k_elem : tensor([0.9900, 0.9900, 0.9900,  ..., 1.0000, 0.9900, 0.9900]), torch.Size([1024])\n",
      "usage 1st : tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        ...,\n",
      "        [1.],\n",
      "        [0.],\n",
      "        [0.]]), torch.Size([1024, 1])\n",
      "usage 2nd : 37.0, torch.Size([])\n",
      "x_l tensor([[ 949,  655,  174,  731,  945,  405,  351,  660,  907, 1021,  524,  409,\n",
      "          441,   22,  821,  733,  785,  594,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
      "          563,  563,  941,  782,  288,   75,  452,  688,  825,  491,  569,  948,\n",
      "          116,  391,  858,  150,  685,  938,  743, 1010]]) torch.Size([1, 128])\n",
      "x_d tensor([[[-0.0453, -0.0447, -0.0489,  ...,  0.0710,  0.0568,  0.0404],\n",
      "         [-0.0150,  0.0003,  0.0227,  ...,  0.0146,  0.0082,  0.0166],\n",
      "         [ 0.0558,  0.0724,  0.0685,  ...,  0.0091,  0.0196,  0.0235],\n",
      "         ...,\n",
      "         [-0.0774, -0.0770, -0.0942,  ..., -0.0350, -0.0227, -0.0140],\n",
      "         [ 0.0252,  0.0348,  0.0400,  ...,  0.0116,  0.0077,  0.0106],\n",
      "         [ 0.0292,  0.0192,  0.0207,  ..., -0.0194, -0.0323, -0.0289]]],\n",
      "       grad_fn=<CloneBackward0>) torch.Size([1, 64, 128])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 949,  655,  174,  731,  945,  405,  351,  660,  907, 1021,  524,  409,\n",
       "           441,   22,  821,  733,  785,  594,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,  563,\n",
       "           563,  563,  941,  782,  288,   75,  452,  688,  825,  491,  569,  948,\n",
       "           116,  391,  858,  150,  685,  938,  743, 1010]]),\n",
       " tensor([[[-0.0453, -0.0447, -0.0489,  ...,  0.0710,  0.0568,  0.0404],\n",
       "          [-0.0150,  0.0003,  0.0227,  ...,  0.0146,  0.0082,  0.0166],\n",
       "          [ 0.0558,  0.0724,  0.0685,  ...,  0.0091,  0.0196,  0.0235],\n",
       "          ...,\n",
       "          [-0.0774, -0.0770, -0.0942,  ..., -0.0350, -0.0227, -0.0140],\n",
       "          [ 0.0252,  0.0348,  0.0400,  ...,  0.0116,  0.0077,  0.0106],\n",
       "          [ 0.0292,  0.0192,  0.0207,  ..., -0.0194, -0.0323, -0.0289]]],\n",
       "        grad_fn=<CloneBackward0>),\n",
       " tensor(8.8970e-07, grad_fn=<DivBackward0>),\n",
       " {'fit': tensor(5.6990e-05, grad_fn=<MeanBackward0>),\n",
       "  'pn': tensor(0.0593, grad_fn=<DivBackward0>),\n",
       "  'entropy': tensor(1.6020),\n",
       "  'used_curr': tensor(37),\n",
       "  'usage': tensor(37.),\n",
       "  'dk': tensor(0.0189)})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f350e67a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet :  torch.Size([1, 128, 128])\n",
      "pixel_shuffle\n",
      "torch.Size([1, 256, 128])\n",
      "torch.Size([1, 512, 128, 1])\n",
      "torch.Size([1, 128, 256])\n",
      "ResNet :  torch.Size([1, 128, 256])\n",
      "pixel_shuffle\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 512, 256, 1])\n",
      "torch.Size([1, 128, 512])\n",
      "ResNet :  torch.Size([1, 128, 512])\n",
      "pixel_shuffle\n",
      "torch.Size([1, 256, 512])\n",
      "torch.Size([1, 512, 512, 1])\n",
      "torch.Size([1, 128, 1024])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1304, -0.0941, -0.0625, -0.4133, -0.0776, -0.2118,  0.0662,\n",
       "          -0.3879, -0.0948, -0.1593, -0.0539, -0.4336, -0.0723, -0.2110,\n",
       "           0.0654, -0.3920, -0.0945, -0.1633, -0.0449, -0.4312, -0.0704,\n",
       "          -0.2152,  0.0656, -0.3896, -0.0881, -0.1687, -0.0452, -0.4329,\n",
       "          -0.0705, -0.2144,  0.0677, -0.3904, -0.0889, -0.1738, -0.0457,\n",
       "          -0.4284, -0.0735, -0.2157,  0.0720, -0.3879, -0.0937, -0.1796,\n",
       "          -0.0448, -0.4319, -0.0718, -0.2156,  0.0647, -0.3867, -0.0943,\n",
       "          -0.1785, -0.0481, -0.4319, -0.0700, -0.2198,  0.0660, -0.3883,\n",
       "          -0.0964, -0.1785, -0.0522, -0.4341, -0.0704, -0.2225,  0.0664,\n",
       "          -0.3935, -0.0967, -0.1836, -0.0549, -0.4337, -0.0701, -0.2239,\n",
       "           0.0693, -0.3930, -0.0957, -0.1903, -0.0557, -0.4344, -0.0742,\n",
       "          -0.2224,  0.0694, -0.3911, -0.0995, -0.1891, -0.0485, -0.4358,\n",
       "          -0.0744, -0.2180,  0.0699, -0.3934, -0.1016, -0.1894, -0.0517,\n",
       "          -0.4408, -0.0739, -0.2161,  0.0706, -0.3996, -0.1029, -0.1888,\n",
       "          -0.0529, -0.4356, -0.0757, -0.2191,  0.0750, -0.4016, -0.0978,\n",
       "          -0.1870, -0.0512, -0.4335, -0.0778, -0.2186,  0.0745, -0.4043,\n",
       "          -0.0983, -0.1860, -0.0500, -0.4373, -0.0816, -0.2176,  0.0743,\n",
       "          -0.4065, -0.0991, -0.1854, -0.0534, -0.4397, -0.0804, -0.2152,\n",
       "           0.0727, -0.4050, -0.0984, -0.1856, -0.0560, -0.4410, -0.0782,\n",
       "          -0.2131,  0.0724, -0.4050, -0.0973, -0.1849, -0.0575, -0.4410,\n",
       "          -0.0773, -0.2115,  0.0701, -0.4053, -0.0973, -0.1872, -0.0564,\n",
       "          -0.4424, -0.0798, -0.2111,  0.0683, -0.4037, -0.0963, -0.1872,\n",
       "          -0.0535, -0.4420, -0.0791, -0.2101,  0.0698, -0.4049, -0.0967,\n",
       "          -0.1902, -0.0545, -0.4402, -0.0802, -0.2122,  0.0709, -0.4085,\n",
       "          -0.0986, -0.1912, -0.0535, -0.4394, -0.0838, -0.2111,  0.0707,\n",
       "          -0.4076, -0.0983, -0.1905, -0.0533, -0.4391, -0.0864, -0.2123,\n",
       "           0.0712, -0.4082, -0.0987, -0.1890, -0.0543, -0.4374, -0.0860,\n",
       "          -0.2122,  0.0721, -0.4083, -0.0987, -0.1875, -0.0533, -0.4363,\n",
       "          -0.0866, -0.2122,  0.0718, -0.4078, -0.1002, -0.1858, -0.0529,\n",
       "          -0.4368, -0.0875, -0.2131,  0.0715, -0.4076, -0.0996, -0.1853,\n",
       "          -0.0533, -0.4375, -0.0866, -0.2130,  0.0711, -0.4080, -0.0997,\n",
       "          -0.1848, -0.0554, -0.4380, -0.0859, -0.2132,  0.0711, -0.4084,\n",
       "          -0.1002, -0.1851, -0.0549, -0.4384, -0.0863, -0.2131,  0.0709,\n",
       "          -0.4086, -0.1000, -0.1849, -0.0552, -0.4386, -0.0857, -0.2132,\n",
       "           0.0709, -0.4084, -0.0999, -0.1852, -0.0552, -0.4389, -0.0860,\n",
       "          -0.2131,  0.0706, -0.4083, -0.1001, -0.1852, -0.0553, -0.4388,\n",
       "          -0.0860, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1851,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1851, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1851, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861, -0.2130,\n",
       "           0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389, -0.0861,\n",
       "          -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553, -0.4389,\n",
       "          -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852, -0.0553,\n",
       "          -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001, -0.1852,\n",
       "          -0.0553, -0.4389, -0.0861, -0.2130,  0.0705, -0.4082, -0.1001,\n",
       "          -0.1852, -0.0553, -0.4389, -0.0860, -0.2130,  0.0705, -0.4082,\n",
       "          -0.1001, -0.1852, -0.0553, -0.4389, -0.0860, -0.2130,  0.0705,\n",
       "          -0.4082, -0.1001, -0.1851, -0.0553, -0.4389, -0.0860, -0.2129,\n",
       "           0.0705, -0.4083, -0.1001, -0.1851, -0.0553, -0.4389, -0.0860,\n",
       "          -0.2128,  0.0705, -0.4083, -0.1000, -0.1850, -0.0553, -0.4389,\n",
       "          -0.0858, -0.2129,  0.0706, -0.4083, -0.0999, -0.1850, -0.0555,\n",
       "          -0.4385, -0.0857, -0.2130,  0.0703, -0.4081, -0.0998, -0.1849,\n",
       "          -0.0555, -0.4392, -0.0852, -0.2132,  0.0706, -0.4078, -0.0991,\n",
       "          -0.1848, -0.0553, -0.4391, -0.0845, -0.2135,  0.0704, -0.4081,\n",
       "          -0.0994, -0.1844, -0.0547, -0.4390, -0.0849, -0.2132,  0.0707,\n",
       "          -0.4075, -0.0990, -0.1845, -0.0544, -0.4395, -0.0855, -0.2130,\n",
       "           0.0699, -0.4071, -0.1002, -0.1845, -0.0538, -0.4397, -0.0855,\n",
       "          -0.2141,  0.0703, -0.4050, -0.0994, -0.1837, -0.0556, -0.4385,\n",
       "          -0.0858, -0.2144,  0.0711, -0.4047, -0.0989, -0.1831, -0.0557,\n",
       "          -0.4352, -0.0818, -0.2139,  0.0720, -0.4033, -0.0990, -0.1828,\n",
       "          -0.0566, -0.4325, -0.0827, -0.2136,  0.0701, -0.4011, -0.1011,\n",
       "          -0.1810, -0.0550, -0.4331, -0.0772, -0.2147,  0.0689, -0.3993,\n",
       "          -0.1021, -0.1784, -0.0549, -0.4342, -0.0744, -0.2185,  0.0706,\n",
       "          -0.3989, -0.1000, -0.1794, -0.0548, -0.4342, -0.0737, -0.2174,\n",
       "           0.0726, -0.4018, -0.1012, -0.1801, -0.0570, -0.4339, -0.0758,\n",
       "          -0.2140,  0.0728, -0.4005, -0.1017, -0.1819, -0.0581, -0.4348,\n",
       "          -0.0753, -0.2136,  0.0729, -0.4014, -0.1005, -0.1794, -0.0606,\n",
       "          -0.4363, -0.0727, -0.2172,  0.0733, -0.4045, -0.1043, -0.1795,\n",
       "          -0.0618, -0.4336, -0.0683, -0.2190,  0.0753, -0.4041, -0.1046,\n",
       "          -0.1797, -0.0603, -0.4344, -0.0708, -0.2191,  0.0741, -0.4036,\n",
       "          -0.1038, -0.1783, -0.0590, -0.4391, -0.0715, -0.2176,  0.0746,\n",
       "          -0.4006, -0.1033, -0.1810, -0.0571, -0.4386, -0.0734, -0.2101,\n",
       "           0.0746, -0.4009, -0.1026, -0.1782, -0.0622, -0.4351, -0.0716,\n",
       "          -0.2069,  0.0764, -0.3961, -0.1049, -0.1775, -0.0660, -0.4312,\n",
       "          -0.0733, -0.2090,  0.0797, -0.3982, -0.0979, -0.1798, -0.0615,\n",
       "          -0.4395, -0.0688, -0.2113,  0.0769, -0.3958, -0.1009, -0.1781,\n",
       "          -0.0616, -0.4398, -0.0727, -0.2103,  0.0787, -0.3927, -0.1044,\n",
       "          -0.1752, -0.0595, -0.4326, -0.0738, -0.2012,  0.0770, -0.4006,\n",
       "          -0.1091, -0.1743, -0.0481, -0.4353, -0.0713, -0.2089,  0.0770,\n",
       "          -0.3916, -0.1106, -0.1815, -0.0434, -0.4325, -0.0704, -0.2110,\n",
       "           0.0687, -0.3898, -0.1079, -0.1821, -0.0405, -0.4337, -0.0702,\n",
       "          -0.2089,  0.0667, -0.3876, -0.1084, -0.1904, -0.0453, -0.4391,\n",
       "          -0.0681, -0.2059,  0.0702, -0.3860, -0.1106, -0.1906, -0.0532,\n",
       "          -0.4380, -0.0653, -0.2051,  0.0647, -0.3958, -0.1021, -0.1889,\n",
       "          -0.0571, -0.4317, -0.0632, -0.2028,  0.0666, -0.3968, -0.1223,\n",
       "          -0.1778, -0.0680, -0.4341, -0.0671, -0.2000,  0.0667, -0.3668,\n",
       "          -0.1352, -0.1583, -0.0894, -0.4298, -0.1131, -0.2175,  0.0715,\n",
       "          -0.3732, -0.1177, -0.1433,  0.0023]]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39b02de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "556d3adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method size of Tensor object at 0x2b9012e4bd10>\n",
      "ResNet :  torch.Size([1, 128, 497])\n",
      "<built-in method size of Tensor object at 0x2b9012e4bd70>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 128, 4], expected input[1, 64, 468] to have 128 channels, but got 64 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5461/3940510466.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5461/1996951236.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5461/1996951236.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;31m#         x = F.pad(x, pad, mode=\"constant\", value=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/venv/lib/python3.7/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    296\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    297\u001b[0m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0;32m--> 298\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 128, 4], expected input[1, 64, 468] to have 128 channels, but got 64 channels instead"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9ebe08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
